{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Ø¨Ø§ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Scikit-learn**"
      ],
      "metadata": {
        "id": "XEMHTF6xRibn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1sG2cS7NNdR",
        "outputId": "032ceac8-97f4-4549-9e5b-e693096f1922"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV2hON7ENEzB",
        "outputId": "fa29cd6f-1d9d-4d9c-b834-f47d8fdda583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Ø³Ù†Ø¯ 1:\n",
            "Ø¢ÛŒÙ†Ø¯Ù‡: 0.4189\n",
            "ØªØºÛŒÛŒØ±: 0.4189\n",
            "Ø®ÙˆØ§Ù‡Ø¯: 0.4189\n",
            "Ø¯Ø§Ø¯: 0.4189\n",
            "Ø±Ø§: 0.4189\n",
            "Ù…ØµÙ†ÙˆØ¹ÛŒ: 0.2474\n",
            "Ù‡ÙˆØ´: 0.2474\n",
            "\n",
            "ðŸ”¹ Ø³Ù†Ø¯ 2:\n",
            "Ø§Ø²: 0.3604\n",
            "Ø§Ø³Øª: 0.3604\n",
            "Ø´Ø§Ø®Ù‡: 0.3604\n",
            "Ù…Ø§Ø´ÛŒÙ†: 0.3604\n",
            "Ù…ØµÙ†ÙˆØ¹ÛŒ: 0.2129\n",
            "Ù‡Ø§ÛŒ: 0.3604\n",
            "Ù‡ÙˆØ´: 0.2129\n",
            "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ: 0.3604\n",
            "ÛŒÚ©ÛŒ: 0.3604\n",
            "\n",
            "ðŸ”¹ Ø³Ù†Ø¯ 3:\n",
            "Ø¢Ù…ÙˆØ²Ø´: 0.4189\n",
            "Ø¯Ø§Ø±Ø¯: 0.4189\n",
            "Ø¯Ø±: 0.4189\n",
            "Ù…ØµÙ†ÙˆØ¹ÛŒ: 0.2474\n",
            "Ù‡ÙˆØ´: 0.2474\n",
            "Ù¾Ø²Ø´Ú©ÛŒ: 0.4189\n",
            "Ú©Ø§Ø±Ø¨Ø±Ø¯: 0.4189\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ø§Ø³Ù†Ø§Ø¯ (Ù‡Ø± Ø³Ù†Ø¯ ÛŒÚ© Ø¬Ù…Ù„Ù‡ ÛŒØ§ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù)\n",
        "documents = [\n",
        "    \"Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ø±Ø§ ØªØºÛŒÛŒØ± Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø¯\",\n",
        "    \"ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† ÛŒÚ©ÛŒ Ø§Ø² Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø³Øª\",\n",
        "    \"Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ù¾Ø²Ø´Ú©ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¯Ø§Ø±Ø¯\"\n",
        "]\n",
        "\n",
        "# Ø³Ø§Ø®Øª TF-IDF Ù…Ø¯Ù„\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Ù†Ù…Ø§ÛŒØ´ Ú©Ù„Ù…Ø§Øª Ùˆ ÙˆØ²Ù† TF-IDF\n",
        "words = vectorizer.get_feature_names_out()\n",
        "\n",
        "for doc_index, doc_vector in enumerate(X.toarray()):\n",
        "    print(f\"\\nðŸ”¹ Ø³Ù†Ø¯ {doc_index + 1}:\")\n",
        "    for word_index, score in enumerate(doc_vector):\n",
        "        if score > 0:\n",
        "            print(f\"{words[word_index]}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ø¨Ø¯ÙˆÙ† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡**"
      ],
      "metadata": {
        "id": "MYbMPUTJRLnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "# Ø³Ù†Ø¯Ù‡Ø§\n",
        "documents = [\n",
        "    \"Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ø±Ø§ ØªØºÛŒÛŒØ± Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø¯\",\n",
        "    \"ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† ÛŒÚ©ÛŒ Ø§Ø² Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø³Øª\",\n",
        "    \"Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ù¾Ø²Ø´Ú©ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¯Ø§Ø±Ø¯\"\n",
        "]\n",
        "\n",
        "# Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´: Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª\n",
        "tokenized_docs = [doc.split() for doc in documents]\n",
        "\n",
        "# ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø³Ù†Ø¯Ù‡Ø§\n",
        "N = len(tokenized_docs)\n",
        "\n",
        "# Ù…Ø­Ø§Ø³Ø¨Ù‡ DF: Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø¯Ø± Ú†Ù†Ø¯ Ø³Ù†Ø¯ Ø¸Ø§Ù‡Ø± Ø´Ø¯Ù‡ØŸ\n",
        "df = {}\n",
        "for doc in tokenized_docs:\n",
        "    unique_words = set(doc)\n",
        "    for word in unique_words:\n",
        "        df[word] = df.get(word, 0) + 1\n",
        "\n",
        "# Ù…Ø­Ø§Ø³Ø¨Ù‡ TF-IDF\n",
        "for doc_index, doc in enumerate(tokenized_docs):\n",
        "    print(f\"\\nðŸ”¹ Ø³Ù†Ø¯ {doc_index + 1}:\")\n",
        "    word_counts = Counter(doc)\n",
        "    total_words = len(doc)\n",
        "\n",
        "    for word in word_counts:\n",
        "        tf = word_counts[word] / total_words\n",
        "        idf = math.log(N / (1 + df[word]))\n",
        "        tfidf = tf * idf\n",
        "        print(f\"{word}: {tfidf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3MfigjkROLB",
        "outputId": "9f45ddc1-9a35-4e5c-8314-858a194db279"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Ø³Ù†Ø¯ 1:\n",
            "Ù‡ÙˆØ´: -0.0411\n",
            "Ù…ØµÙ†ÙˆØ¹ÛŒ: -0.0411\n",
            "Ø¢ÛŒÙ†Ø¯Ù‡: 0.0579\n",
            "Ø±Ø§: 0.0579\n",
            "ØªØºÛŒÛŒØ±: 0.0579\n",
            "Ø®ÙˆØ§Ù‡Ø¯: 0.0579\n",
            "Ø¯Ø§Ø¯: 0.0579\n",
            "\n",
            "ðŸ”¹ Ø³Ù†Ø¯ 2:\n",
            "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ: 0.0507\n",
            "Ù…Ø§Ø´ÛŒÙ†: 0.0507\n",
            "ÛŒÚ©ÛŒ: 0.0507\n",
            "Ø§Ø²: 0.0507\n",
            "Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒ: 0.0507\n",
            "Ù‡ÙˆØ´: -0.0360\n",
            "Ù…ØµÙ†ÙˆØ¹ÛŒ: -0.0360\n",
            "Ø§Ø³Øª: 0.0507\n",
            "\n",
            "ðŸ”¹ Ø³Ù†Ø¯ 3:\n",
            "Ù‡ÙˆØ´: -0.0360\n",
            "Ù…ØµÙ†ÙˆØ¹ÛŒ: -0.0360\n",
            "Ø¯Ø±: 0.0507\n",
            "Ù¾Ø²Ø´Ú©ÛŒ: 0.0507\n",
            "Ùˆ: 0.0507\n",
            "Ø¢Ù…ÙˆØ²Ø´: 0.0507\n",
            "Ú©Ø§Ø±Ø¨Ø±Ø¯: 0.0507\n",
            "Ø¯Ø§Ø±Ø¯: 0.0507\n"
          ]
        }
      ]
    }
  ]
}